{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named keras.models",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1dd4400efabf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named keras.models"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data is saved as a dataframe with two column names: label and review\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Myles\\\\Documents\\\\Napier Data Science\\\\Dissertation\\\\Test data set\\\\factorsandreturns.csv\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['return'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('calendardate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,2:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid = df[0:6710,:], df[6710:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('calendardate',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accoci</th>\n",
       "      <th>assets</th>\n",
       "      <th>assetsavg</th>\n",
       "      <th>assetsc</th>\n",
       "      <th>assetsnc</th>\n",
       "      <th>assetturnover</th>\n",
       "      <th>bvps</th>\n",
       "      <th>capex</th>\n",
       "      <th>cashneq</th>\n",
       "      <th>cor</th>\n",
       "      <th>...</th>\n",
       "      <th>sgna</th>\n",
       "      <th>sharefactor</th>\n",
       "      <th>sharesbas</th>\n",
       "      <th>shareswadil</th>\n",
       "      <th>taxassets</th>\n",
       "      <th>taxexp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>tbvps</th>\n",
       "      <th>workingcapital</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>-408000000</td>\n",
       "      <td>8.541000e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3.848000e+09</td>\n",
       "      <td>4.693000e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>14.362</td>\n",
       "      <td>-35000000</td>\n",
       "      <td>2.247000e+09</td>\n",
       "      <td>585000000</td>\n",
       "      <td>...</td>\n",
       "      <td>356000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>318533054</td>\n",
       "      <td>322000000</td>\n",
       "      <td>0</td>\n",
       "      <td>49000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.965</td>\n",
       "      <td>2.677000e+09</td>\n",
       "      <td>0.044418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONDK</th>\n",
       "      <td>-503000</td>\n",
       "      <td>1.139933e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.814</td>\n",
       "      <td>-1211000</td>\n",
       "      <td>1.202230e+08</td>\n",
       "      <td>50767000</td>\n",
       "      <td>...</td>\n",
       "      <td>23952000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75046285</td>\n",
       "      <td>79372491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.257</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.079075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONDS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.206063e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002910e+06</td>\n",
       "      <td>2.031530e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-134833</td>\n",
       "      <td>5.162510e+05</td>\n",
       "      <td>6427</td>\n",
       "      <td>...</td>\n",
       "      <td>1214169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50463732</td>\n",
       "      <td>24033664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-9.798867e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONTX</th>\n",
       "      <td>-7000</td>\n",
       "      <td>2.313600e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.310400e+07</td>\n",
       "      <td>3.200000e+04</td>\n",
       "      <td>0</td>\n",
       "      <td>1.914</td>\n",
       "      <td>0</td>\n",
       "      <td>2.238400e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1729000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5674220</td>\n",
       "      <td>5674125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.077</td>\n",
       "      <td>1.489700e+07</td>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONVO</th>\n",
       "      <td>0</td>\n",
       "      <td>4.262500e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4.011700e+07</td>\n",
       "      <td>2.508000e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-11000</td>\n",
       "      <td>3.748200e+07</td>\n",
       "      <td>125000</td>\n",
       "      <td>...</td>\n",
       "      <td>3640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115890335</td>\n",
       "      <td>113993237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374</td>\n",
       "      <td>3.682600e+07</td>\n",
       "      <td>-0.108527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           accoci        assets  assetsavg       assetsc      assetsnc  \\\n",
       "ticker                                                                   \n",
       "A      -408000000  8.541000e+09          0  3.848000e+09  4.693000e+09   \n",
       "ONDK      -503000  1.139933e+09          0  0.000000e+00  0.000000e+00   \n",
       "ONDS            0  1.206063e+06          0  1.002910e+06  2.031530e+05   \n",
       "ONTX        -7000  2.313600e+07          0  2.310400e+07  3.200000e+04   \n",
       "ONVO            0  4.262500e+07          0  4.011700e+07  2.508000e+06   \n",
       "\n",
       "        assetturnover    bvps     capex       cashneq        cor  ...  \\\n",
       "ticker                                                            ...   \n",
       "A                   0  14.362 -35000000  2.247000e+09  585000000  ...   \n",
       "ONDK                0   3.814  -1211000  1.202230e+08   50767000  ...   \n",
       "ONDS                0  -0.412   -134833  5.162510e+05       6427  ...   \n",
       "ONTX                0   1.914         0  2.238400e+07          0  ...   \n",
       "ONVO                0   0.341    -11000  3.748200e+07     125000  ...   \n",
       "\n",
       "             sgna  sharefactor  sharesbas  shareswadil  taxassets    taxexp  \\\n",
       "ticker                                                                        \n",
       "A       356000000          1.0  318533054    322000000          0  49000000   \n",
       "ONDK     23952000          1.0   75046285     79372491          0         0   \n",
       "ONDS      1214169          1.0   50463732     24033664          0         0   \n",
       "ONTX      1729000          1.0    5674220      5674125          0         0   \n",
       "ONVO      3640000          1.0  115890335    113993237          0         0   \n",
       "\n",
       "        taxliabilities   tbvps  workingcapital    return  \n",
       "ticker                                                    \n",
       "A                    0  15.965    2.677000e+09  0.044418  \n",
       "ONDK                 0  15.257    0.000000e+00 -0.079075  \n",
       "ONDS                 0   0.049   -9.798867e+06  0.000000  \n",
       "ONTX                 0   4.077    1.489700e+07  0.137984  \n",
       "ONVO                 0   0.374    3.682600e+07 -0.108527  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(0, 6710, None), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-55dd4088f98f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6710\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6710\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\ipykernel_py3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ipykernel_py3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2654\u001b[0m                                  'backfill or nearest lookups')\n\u001b[0;32m   2655\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2656\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2657\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(0, 6710, None), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "train,valid = df[0:6710,:], df[6710:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-9b1431420e98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#converting dataset into x_train and y_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscaled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train,valid = X[0:6710,:], X[6710:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for i in train:\n",
    "    x_train.append(X[:,:-1])\n",
    "    y_train.append(X[:,-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-45c0a744f3e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_data\n",
    "train,test = X[0:6710], X[6710:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train[:, 0:-1], train[:, -1]\n",
    "X = X.reshape(X.shape[0], 1, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.71669593e-01, 2.49859580e-03, 0.00000000e+00, ...,\n",
       "         4.01422003e-06, 3.15987378e-03, 2.50516316e-01]],\n",
       "\n",
       "       [[7.79893383e-01, 3.33477556e-04, 0.00000000e+00, ...,\n",
       "         4.01422003e-06, 3.01974283e-03, 2.31451808e-01]],\n",
       "\n",
       "       [[7.79903534e-01, 3.52823317e-07, 0.00000000e+00, ...,\n",
       "         4.01422003e-06, 9.69832854e-06, 2.31382025e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[7.79882606e-01, 5.48124517e-04, 0.00000000e+00, ...,\n",
       "         4.01422003e-06, 4.77779249e-02, 2.31451808e-01]],\n",
       "\n",
       "       [[7.78512220e-01, 5.45992183e-04, 0.00000000e+00, ...,\n",
       "         4.01422003e-06, 4.73238848e-04, 2.31224679e-01]],\n",
       "\n",
       "       [[7.76305221e-01, 1.41991973e-02, 0.00000000e+00, ...,\n",
       "         4.01422003e-06, 9.16185263e-02, 2.31451808e-01]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calendardate</th>\n",
       "      <th>accoci</th>\n",
       "      <th>assets</th>\n",
       "      <th>assetsavg</th>\n",
       "      <th>assetsc</th>\n",
       "      <th>assetsnc</th>\n",
       "      <th>assetturnover</th>\n",
       "      <th>bvps</th>\n",
       "      <th>capex</th>\n",
       "      <th>cashneq</th>\n",
       "      <th>...</th>\n",
       "      <th>sgna</th>\n",
       "      <th>sharefactor</th>\n",
       "      <th>sharesbas</th>\n",
       "      <th>shareswadil</th>\n",
       "      <th>taxassets</th>\n",
       "      <th>taxexp</th>\n",
       "      <th>taxliabilities</th>\n",
       "      <th>tbvps</th>\n",
       "      <th>workingcapital</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>30/09/2018</td>\n",
       "      <td>-408000000</td>\n",
       "      <td>8.541000e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3.848000e+09</td>\n",
       "      <td>4.693000e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>14.362</td>\n",
       "      <td>-35000000</td>\n",
       "      <td>2.247000e+09</td>\n",
       "      <td>...</td>\n",
       "      <td>356000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>318533054</td>\n",
       "      <td>322000000</td>\n",
       "      <td>0</td>\n",
       "      <td>49000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.965</td>\n",
       "      <td>2.677000e+09</td>\n",
       "      <td>0.044418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONDK</th>\n",
       "      <td>30/09/2018</td>\n",
       "      <td>-503000</td>\n",
       "      <td>1.139933e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>3.814</td>\n",
       "      <td>-1211000</td>\n",
       "      <td>1.202230e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>23952000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75046285</td>\n",
       "      <td>79372491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.257</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.079075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONDS</th>\n",
       "      <td>30/09/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206063e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>1.002910e+06</td>\n",
       "      <td>2.031530e+05</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>-134833</td>\n",
       "      <td>5.162510e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>1214169</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50463732</td>\n",
       "      <td>24033664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-9.798867e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONTX</th>\n",
       "      <td>30/09/2018</td>\n",
       "      <td>-7000</td>\n",
       "      <td>2.313600e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>2.310400e+07</td>\n",
       "      <td>3.200000e+04</td>\n",
       "      <td>0</td>\n",
       "      <td>1.914</td>\n",
       "      <td>0</td>\n",
       "      <td>2.238400e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1729000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5674220</td>\n",
       "      <td>5674125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.077</td>\n",
       "      <td>1.489700e+07</td>\n",
       "      <td>0.137984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONVO</th>\n",
       "      <td>30/09/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>4.262500e+07</td>\n",
       "      <td>0</td>\n",
       "      <td>4.011700e+07</td>\n",
       "      <td>2.508000e+06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>-11000</td>\n",
       "      <td>3.748200e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>3640000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115890335</td>\n",
       "      <td>113993237</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374</td>\n",
       "      <td>3.682600e+07</td>\n",
       "      <td>-0.108527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       calendardate     accoci        assets  assetsavg       assetsc  \\\n",
       "ticker                                                                  \n",
       "A        30/09/2018 -408000000  8.541000e+09          0  3.848000e+09   \n",
       "ONDK     30/09/2018    -503000  1.139933e+09          0  0.000000e+00   \n",
       "ONDS     30/09/2018          0  1.206063e+06          0  1.002910e+06   \n",
       "ONTX     30/09/2018      -7000  2.313600e+07          0  2.310400e+07   \n",
       "ONVO     30/09/2018          0  4.262500e+07          0  4.011700e+07   \n",
       "\n",
       "            assetsnc  assetturnover    bvps     capex       cashneq  ...  \\\n",
       "ticker                                                               ...   \n",
       "A       4.693000e+09              0  14.362 -35000000  2.247000e+09  ...   \n",
       "ONDK    0.000000e+00              0   3.814  -1211000  1.202230e+08  ...   \n",
       "ONDS    2.031530e+05              0  -0.412   -134833  5.162510e+05  ...   \n",
       "ONTX    3.200000e+04              0   1.914         0  2.238400e+07  ...   \n",
       "ONVO    2.508000e+06              0   0.341    -11000  3.748200e+07  ...   \n",
       "\n",
       "             sgna  sharefactor  sharesbas  shareswadil  taxassets    taxexp  \\\n",
       "ticker                                                                        \n",
       "A       356000000          1.0  318533054    322000000          0  49000000   \n",
       "ONDK     23952000          1.0   75046285     79372491          0         0   \n",
       "ONDS      1214169          1.0   50463732     24033664          0         0   \n",
       "ONTX      1729000          1.0    5674220      5674125          0         0   \n",
       "ONVO      3640000          1.0  115890335    113993237          0         0   \n",
       "\n",
       "        taxliabilities   tbvps  workingcapital    return  \n",
       "ticker                                                    \n",
       "A                    0  15.965    2.677000e+09  0.044418  \n",
       "ONDK                 0  15.257    0.000000e+00 -0.079075  \n",
       "ONDS                 0   0.049   -9.798867e+06  0.000000  \n",
       "ONTX                 0   4.077    1.489700e+07  0.137984  \n",
       "ONVO                 0   0.374    3.682600e+07 -0.108527  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('calendardate', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04441812, -0.07907543,  0.        , ..., -0.05237569,\n",
       "       -0.12205742, -0.0516129 ])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = df['return'].values\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.drop('return', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.0800000e+08,  8.5410000e+09,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  1.5965000e+01,  2.6770000e+09],\n",
       "       [-5.0300000e+05,  1.1399330e+09,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  1.5257000e+01,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  1.2060630e+06,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  4.9000000e-02, -9.7988670e+06],\n",
       "       ...,\n",
       "       [-1.8301900e+08,  1.1823650e+09,  0.0000000e+00, ...,\n",
       "         4.2249000e+07,  1.7257000e+01,  3.2402200e+08],\n",
       "       [-2.3518700e+08,  3.5408629e+10,  0.0000000e+00, ...,\n",
       "         0.0000000e+00,  2.9842070e+03,  0.0000000e+00],\n",
       "       [ 0.0000000e+00,  1.6184000e+07,  0.0000000e+00, ...,\n",
       "         6.8800000e+05,  5.0100000e-01,  7.9710000e+06]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04441812, -0.07907543,  0.        , ..., -0.05237569,\n",
       "       -0.12205742, -0.0516129 ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-6c480f924d11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_cols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    163\u001b[0m                     \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(n_cols,)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=1, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8387, 82)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80% training 20% validation split :6710 \n",
    "\n",
    "train = df.iloc[0:6710,:]\n",
    "valid = df.iloc[6710:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\envs\\keras\\lib\\site-packages\\sklearn\\preprocessing\\data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#converting dataset into x_train and y_train\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = [], []\n",
    "for i in range(len(train)):\n",
    "    x_train.append(scaled_data[i,0])\n",
    "    y_train.append(scaled_data[i,0])\n",
    "x_train, y_train = np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77166959, 0.77989338, 0.77990353, ..., 0.77988261, 0.77851222,\n",
       "       0.77630522])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-12c1997161e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0],x_train.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "reviews_train, reviews_test, y_train, y_test = train_test_split(reviews, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets\n",
    "\n",
    "The Keras library allows us to quickly define a CNN architecture, train and evaluate a CNN model with minimal effort. But firstly, we will need to introduce a new concept: __Embeddings__\n",
    "\n",
    "1. Word Embedding \n",
    "\n",
    "Word embeddings are approaches for representing words and documents using vectors. Word embeddings offer an improvement over the traditional bag-of-word encoding paradigms where large sparse vectors are used to represent each word or texts. This way of representing words and texts introduce the sparsity problem, because the number of unique words in a document can be vast and a given word or text is represented by a large vector comprised mostly of zero values. \n",
    "\n",
    "Instead, in an embedding, words are represented by __dense vectors__ (smaller vectors with minimal zero values) where a vector represents the projection of the word into a continuous vector space.\n",
    "\n",
    "The position of a word within the vector space is learnt from text and is based on the surrounding words of a word when it is used. The __position of a word__ in the learnt vector space is known as its __embedding__.\n",
    "\n",
    "There are a few popular ways of learning word embeddings from text such as Word2Vec, Doc2Vec, Glove and ELMO. \n",
    "\n",
    "In addition to these popular methods, word embeddings can be learned as part of a deep learning model as we will see below. \n",
    "\n",
    "2. Keras Embedding Layer\n",
    "\n",
    "Keras offers an Embedding layer that can be used for training neural networks using text data. Keras' Embedding layer takes as input integer encoded data, so that each word is represented by a unique integer. We can use tokenisation to pre-process the data. \n",
    "\n",
    "Then, the weights of the Embedding layer are randomly initialized and it is trained to learn an embedding for all of the words in the training dataset.\n",
    "\n",
    "The Embedding layer is defined as the first hidden layer of a network. It must specify 3 arguments:\n",
    "\n",
    "1. __input_dim__: the size of the vocabulary in the text data. For example, if your data is integer encoded to values between 0-199, then the input_dim will be 200.\n",
    "2. __output_dim__: the size of the vector space in which words will be embedded. It is a user-specified value, so test different values for your task.\n",
    "3. __input_length__: This is the length of input sequences, as you would define for any input layer of a Keras model. For example, if all of your input documents are comprised of 1000 words, this would be 1000.\n",
    "\n",
    "For example, below we define an Embedding layer with a vocabulary of 1922 (e.g. integer encoded words from 0 to 1921, inclusive), a vector space of 50 dimensions in which words will be embedded, and input documents that have 50 words each.\n",
    "\n",
    "__Embedding(1922, 50, input_length=30)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the tokenizer: https://keras.io/preprocessing/text/ \n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "\n",
    "#Use tokenisation only on the training data!\n",
    "tokenizer.fit_on_texts(reviews_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(reviews_train)\n",
    "X_test = tokenizer.texts_to_sequences(reviews_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "\n",
    "print(reviews_train[0])\n",
    "print(X_train[0])\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above method will result in text sequences of variable length of words. To counter this, we can use pad_sequence() which pads the sequence of words with zeros. Additionally you would want to add a maxlen parameter to specify how long the sequences should be. For more oprions of the __pad_sequence__ function look here:  https://keras.io/preprocessing/sequence/ \n",
    "\n",
    "In the following code, you can see how to pad sequences with Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 50\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw during the workbook/lecture, CNNs is just a sequence of different types of layers. Keras allows us to \"build\" this sequence of layers easily. First, we need to define the type of model, in this case Sequential as follows:\n",
    "\n",
    "__model = Sequential()__\n",
    "\n",
    "Then we can add layers as we want, e.g. we can add Convolutional Layers (e.g. Conv1D), Pooling layers (e.g. MaxPooling1D), Fully Connected layers (e.g. Dense) and so on. For a full list of acceptable layers, please see the Keras documentation: https://keras.io/layers/about-keras-layers/ \n",
    "\n",
    "Then you simply add the layers of your choice as follows:\n",
    "\n",
    "__model.add(layers.Dense(1, activation='sigmoid'))__\n",
    "\n",
    "As you see from the example, you can choose the activation function you want as well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)) #https://keras.io/layers/embeddings/ \n",
    "model.add(layers.Conv1D(128, 5, activation='relu')) #https://keras.io/layers/convolutional/\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#spend some time familiarising with the keras documentation. \n",
    "#It is imporssible to remember all the options available but you should be able to remember the basics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now see that we have 129,529 new parameters to train. The 93,950 parameters are derived from vocab_size times the embedding_dim (1879 x 50). These weights of the embedding layer are initialized with random weights and are then adjusted through backpropagation during training. This model takes the words as they come in the order of the sentences as input vectors. You can train it with the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = model.fit(X_train, y_train, epochs=10, verbose=False, validation_data=(X_test, y_test), batch_size=10)\n",
    "#details about the model: https://keras.io/models/model/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the accuracy during training and testing as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can observe how fast the model learns by plotting the historical data of accuracy and loss. We can see that our model would reach a good level of accuracy after only three epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(training):\n",
    "    acc = training.history['acc']\n",
    "    val_acc = training.history['val_acc']\n",
    "    loss = training.history['loss']\n",
    "    val_loss = training.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a walk through on how to create a train a CNN. As an exercise, familiarise yourself with the Keras exercise and try to add new layers to the CNN architcture / change the values of variables and observe what is happening. You can also try a CNN with the assignment data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
